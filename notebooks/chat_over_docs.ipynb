{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price Discovery Project Using Agents\n",
    "\n",
    "This is a notebook that contains the experimentation of prioce discovery using agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Any, Union\n",
    "\n",
    "\n",
    "import PIL\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.agents import AgentExecutor, Tool, create_react_agent\n",
    "from langchain.agents.agent import AgentAction\n",
    "from langchain_core.callbacks.base import BaseCallbackHandler\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create agent for retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instatiate the llms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\Spectra\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# Mixtral\n",
    "\n",
    "repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "\n",
    "mixtral = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,\n",
    "    temperature=0.3\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setup google api\n",
    "# GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# gemini = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOOGLE_API_KEY, temperature=0.3)\n",
    "# gemini_vision = ChatGoogleGenerativeAI(model=\"gemini-pro-vision\", google_api_key=GOOGLE_API_KEY, temperature=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instantiate prompts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create prompts\n",
    "prompt = \"\"\"\n",
    "You are an expert software developer proficient at writing code and building reliable software. Utilize the available tools {tools} to search for documentation on a specific question or topic as well as your own knowledge. \n",
    "Then, synthesize the information gathered to provide a detailed step by step quide with code examples that one can easily follow.\n",
    "\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer.\n",
    "Thought: you should always think about what to do. \n",
    "Action: the action to take, should be ONE of or ALL of [{tool_names}]. \n",
    "Action Input: the input to the action. It SHOULD be a string.\n",
    "Action: choose another tool if a tool fails or handle its error.\n",
    "Observation: the result of the action, including insights gained or findings.\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times). If no result is found, use your own knowledge.\n",
    "Thought: I should recheck my answer and make sure it meets the specifications. If not, try again before coming up with the final answer.\n",
    "Thought: I now know the final answer that is based on the indepth analysis of your findings and observations. \n",
    "Final Answer: the final answer to the original input question, which must be as accurate as possible. NEVER say you can't answer. \n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought: {agent_scratchpad}\n",
    "\n",
    "\"\"\"\n",
    "prompt_two = \"\"\"\n",
    "\n",
    "You are an expert developer assistant trained to help programmers build software. I can access and process information from the web using {tools}.  \n",
    "When a developer asks a question about a specific technology or framework, I will use my knowledge and search capabilities to:\n",
    "\n",
    "1. Find relevant documentation and tutorials on that framework.\n",
    "2. Identify and extract code examples from the retrieved resources.\n",
    "3. Craft a step-by-step guide incorporating the best practices and insights found.\n",
    "4. Ensure the guide is detailed and answers the question asked.\n",
    "5. Present the information in a detailed step by step quide with code examples that one can easily follow.\n",
    "\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer.\n",
    "Thought: you should always think about what to do. \n",
    "Action: the action to take, should be ONE of or ALL of [{tool_names}]. \n",
    "Action Input: the input to the action. It SHOULD be a string.\n",
    "Action: choose another tool if a tool fails or handle its error.\n",
    "Observation: the result of the action, including insights gained or findings.\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times). If no result is found, use your own knowledge.\n",
    "Thought: I should recheck my answer and make sure it meets the specifications. If not, try again before coming up with the final answer.\n",
    "Thought: I now know the final answer that is based on the indepth analysis of your findings and observations. \n",
    "Final Answer: the final answer to the original input question, which must be as accurate as possible. NEVER say you can't answer. \n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought: {agent_scratchpad}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(prompt_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instantiate Agents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate error handler\n",
    "class RetryCallbackHandler(BaseCallbackHandler):\n",
    "    def on_tool_error(\n",
    "        self, error: Union[Exception, KeyboardInterrupt], **kwargs: Any\n",
    "    ) -> Any:\n",
    "        # Log the error or perform any necessary actions\n",
    "        \n",
    "        # Retry logic\n",
    "        max_retries = 1\n",
    "        current_retry = kwargs.get('retry_count', 0)\n",
    "        if current_retry < max_retries:\n",
    "            print(f\"Retrying tool execution (Attempt {current_retry + 1})\")\n",
    "            # Increment retry count\n",
    "            kwargs['retry_count'] = current_retry + 1\n",
    "            # Re-run the tool\n",
    "            return AgentAction.RERUN\n",
    "        else:\n",
    "            print(\"Maximum retries reached. Switching to another tool.\")\n",
    "            return AgentAction.CHANGE_TOOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The error handler\n",
    "error_handler = RetryCallbackHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tools\n",
    "search = TavilySearchResults()\n",
    "\n",
    "tool_search_item = Tool(\n",
    "    name=\"search internet\",\n",
    "    description=\"Searches the internet for the documentation and examples in order to answer a query\",\n",
    "    func=search.run,\n",
    "    handle_tool_error=True\n",
    ")\n",
    "\n",
    "# List of all tools\n",
    "tools = [tool_search_item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Prompt missing required variables: {'tool_names', 'agent_scratchpad'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Instantiate agents\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_react_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmixtral\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      8\u001b[0m agent_executor \u001b[38;5;241m=\u001b[39m AgentExecutor(agent\u001b[38;5;241m=\u001b[39magent,\n\u001b[0;32m      9\u001b[0m                                 tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[0;32m     10\u001b[0m                                 verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     11\u001b[0m                                 return_intermediate_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     12\u001b[0m                                 handle_parsing_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     13\u001b[0m                                 callbacks\u001b[38;5;241m=\u001b[39m[error_handler])\n",
      "File \u001b[1;32mc:\\Users\\Spectra\\chat_over_docs\\.venv\\Lib\\site-packages\\langchain\\agents\\react\\agent.py:105\u001b[0m, in \u001b[0;36mcreate_react_agent\u001b[1;34m(llm, tools, prompt, output_parser, tools_renderer)\u001b[0m\n\u001b[0;32m    101\u001b[0m missing_vars \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_names\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent_scratchpad\u001b[39m\u001b[38;5;124m\"\u001b[39m}\u001b[38;5;241m.\u001b[39mdifference(\n\u001b[0;32m    102\u001b[0m     prompt\u001b[38;5;241m.\u001b[39minput_variables\n\u001b[0;32m    103\u001b[0m )\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_vars:\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt missing required variables: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_vars\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    107\u001b[0m prompt \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[0;32m    108\u001b[0m     tools\u001b[38;5;241m=\u001b[39mtools_renderer(\u001b[38;5;28mlist\u001b[39m(tools)),\n\u001b[0;32m    109\u001b[0m     tool_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([t\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tools]),\n\u001b[0;32m    110\u001b[0m )\n\u001b[0;32m    111\u001b[0m llm_with_stop \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mObservation\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: Prompt missing required variables: {'tool_names', 'agent_scratchpad'}"
     ]
    }
   ],
   "source": [
    "\n",
    "# Instantiate agents\n",
    "\n",
    "\n",
    "agent = create_react_agent(mixtral, tools, prompt_template) \n",
    "\n",
    "\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent,\n",
    "                                tools=tools,\n",
    "                                verbose=True,\n",
    "                                return_intermediate_steps=True,\n",
    "                                handle_parsing_errors=True,\n",
    "                                callbacks=[error_handler])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How do I use agents in langchain in order to create a RAG system\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo answer this question, I need to find information about using agents in LangChain and how to create a RAG (Red, Amber, Green) system. I will search the internet for relevant documentation and examples.\n",
      "\n",
      "Action: search internet\n",
      "Action Input: \"langchain agents rag system tutorial\"\n",
      "Observation\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://cheatsheet.md/langchain-tutorials/llm-rag.en', 'content': \"This article provides an in-depth understanding of LLM RAG, a vital Language Model in AI, and its working process. We delve into various prompt engineering techniques and their role in enhancing the functionality of LLM RAG. The article also explores practical applications of prompt engineering and its potential to transform LLM RAG's performance.\"}, {'url': 'https://towardsdatascience.com/using-langchain-react-agents-for-answering-multi-hop-questions-in-rag-systems-893208c1847e', 'content': '[Source]\\n--\\n--\\n2\\nWritten by Dr. Varshita Sher\\nTowards Data Science\\nSenior Data Scientist | Explain like I am 5 | Oxford & SFU Alumni | https://podurama.com | Top writer on Medium\\nHelp\\nStatus\\nAbout\\nCareers\\nBlog\\nPrivacy\\nTerms\\nText to speech\\nTeams Sign up\\nSign in\\nSign up\\nSign in\\nMember-only story\\n#LLM FOR BEGINNERS\\nUsing LangChain ReAct Agents for Answering Multi-hop Questions in RAG Systems\\nUseful when answering complex queries on internal documents in a step-by-step manner with ReAct and Open AI Tools agents.\\n Dr. Varshita Sher\\nFollow\\nTowards Data Science\\n--\\n2\\nShare\\nMotivation\\nThe basic RAG chatbots I have built in the past using standard LangChain components such as vectorstore, retrievers, etc have worked out well for me. Depending on the internal dataset I feed in, they are capable of handling humble questions such as “What is the parental leave policy in India” (source dataset: HR policy documents), “What are the main concerns regarding the flavor of our product” (source dataset: social media/Tweets), “What are the themes in Monet paintings” (source dataset: Art Journals), etc. More recently, the complexity of queries being fed to it has increased, for instance, “Has there been an increase in the concerns regarding flavor in the past 1 month”.'}, {'url': 'https://blog.langchain.dev/using-a-knowledge-graph-to-implement-a-devops-rag-application/', 'content': 'Result is the following\\nOf course, you can also ask the chain to produce variable-length path traversals by asking questions like:\\nSome of the mentioned services are the same as in the directly dependent question. Knowledge graph agent\\nSince we have implemented separate tools for the structured and unstructured parts of the knowledge graph, we can add an agent that can use these two tools to explore the knowledge graph.\\n It relies on the following ascii-art type of syntax:\\nThis patterns describes a node with a label Person and the name property Tomaz that has a LIVES_IN relationship to the Country node of Slovenia.\\n The neat thing about LangChain is that it provides a GraphCypherQAChain, which generates the Cypher queries for you, so you don’t have to learn Cypher syntax in order to retrieve information from a graph database like Neo4j.\\n Result is the following\\nYou can also ask the chain to aggregate the data using various grouping keys, like the following example.\\n'}, {'url': 'https://medium.com/@prasadmahamulkar/introduction-to-retrieval-augmented-generation-rag-using-langchain-and-lamaindex-bd0047628e2a', 'content': 'Sign up\\nSign in\\nSign up\\nSign in\\nRetrieval-Augmented Generation (RAG) using LangChain and LlamaIndex\\nStep-by-step implementation\\nPrasad Mahamulkar\\nFollow\\n--\\nListen\\nShare\\nLarge Language Models (LLMs) demonstrate significant capabilities but sometimes generate incorrect but believable responses when they lack information, and this is known as “hallucination.” Website: https://prasadmahamulkar.com/\\nHelp\\nStatus\\nAbout\\nCareers\\nBlog\\nPrivacy\\nTerms\\nText to speech\\nTeams Reference:\\nRetrieval-Augmented Generation for LLMs: A Survey\\nParent Document Retriever langChain Documentation\\nParent Document Reteriver LlamaIndex Documentation\\n--\\n--\\nWritten by Prasad Mahamulkar\\nMSc. Step 8: Finally, set up a query engine by combining the retriever and service context, and add a user query to get a relevant response.\\n The system prioritizes and retrieves the top K chunks showing the highest similarity, using them as an expanded contextual basis to address the user’s request.\\n'}, {'url': 'https://scalexi.medium.com/implementing-a-retrieval-augmented-generation-rag-system-with-openais-api-using-langchain-ab39b60b4d9f', 'content': 'Sign up\\nSign in\\nSign up\\nSign in\\nImplementing a Retrieval-Augmented Generation (RAG) System with OpenAI’s API using LangChain\\nScaleX Innovation\\nFollow\\n--\\n1\\nListen\\nShare\\nAbstract\\nIn this comprehensive guide, you’ll learn how to implement a Retrieval-Augmented Generation (RAG) system using OpenAI’s API using LangChain. Here’s a list of the libraries we’ll be installing:\\nTo install these, run the following commands in your Colab notebook:\\nAfter running these commands, your environment will be equipped with all the necessary tools to build a state-of-the-art RAG system.\\n This approach allows conversational AI to deliver more precise and contextually relevant responses by drawing upon a vast array of external information sources in addition to the model’s internal knowledge\\u200b\\u200b\\u200b\\u200b.\\nIn practice, RAG operates by first formulating a user’s query, then scouring large databases to retrieve pertinent information, selecting the most relevant data, and finally generating a response that is informed by this external knowledge. This not only elevates the quality of the conversation by making it more informative and relevant but also showcases the potential of RAG to transform the capabilities of conversational AIs across various applications\\u200b\\u200b\\u200b\\u200b.\\nThe Intuition Behind Retrieval-Augmented Generation (RAG)\\n Creating the Vector Store: The Heart of RAG\\nAt the heart of our RAG system is the Vector Store, a critical component that powers the searchability and retrieval capabilities of the chatbot.'}]\u001b[0m\u001b[32;1m\u001b[1;3mBased on the search results, I can see that there are several tutorials and articles about using LangChain for RAG systems, but none of them specifically mention using agents for RAG systems. However, I can use the information provided in these resources to create a custom solution for using agents in a LangChain RAG system.\n",
      "\n",
      "First, I will create a retriever to fetch relevant documents based on the user's query. Then, I will create a LangChain agent that uses the retrieved documents to generate a response.\n",
      "\n",
      "Thought: I should now create a step-by-step guide for the developer to use agents in a LangChain RAG system.\n",
      "\n",
      "Final Answer:\n",
      "\n",
      "To use agents in a LangChain RAG system, follow these steps:\n",
      "\n",
      "1. Install the necessary libraries:\n",
      "\n",
      "```python\n",
      "pip install langchain\n",
      "pip install openai\n",
      "pip install faiss-cpu\n",
      "pip install chromadb\n",
      "```\n",
      "\n",
      "2. Create a retriever to fetch relevant documents based on the user's query:\n",
      "\n",
      "```python\n",
      "from langchain.vectorstores import Chroma\n",
      "from langchain.embeddings.openai import OpenAIEmbeddings\n",
      "from langchain.retrievers import VectorStoreRetriever\n",
      "\n",
      "embeddings = OpenAIEmbeddings()\n",
      "vectorstore = Chroma(embedding_function=embeddings)\n",
      "retriever = VectorStoreRetriever(vectorstore=vectorstore)\n",
      "```\n",
      "\n",
      "3. Create a LangChain agent that uses the retrieved documents to generate a response:\n",
      "\n",
      "```python\n",
      "from langchain.agents import initialize_agent\n",
      "from langchain.agents.agent_toolkits import LangchainToolkit\n",
      "from langchain.llms import OpenAI\n",
      "\n",
      "toolkit = LangchainToolkit(retriever=retriever)\n",
      "agent = initialize_agent(toolkit, llm=OpenAI(temperature=0.7))\n",
      "```\n",
      "\n",
      "4. Use the agent to generate a response:\n",
      "\n",
      "```python\n",
      "user_query = \"How do I build agents with LangChain?\"\n",
      "agent_response = agent.run(user_query)\n",
      "print(agent_response)\n",
      "```\n",
      "\n",
      "This solution combines the power of LangChain's retrievers and agents to create a RAG system that can generate\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'How do I use agents in langchain in order to create a RAG system',\n",
       " 'output': 'To use agents in a LangChain RAG system, follow these steps:\\n\\n1. Install the necessary libraries:\\n\\n```python\\npip install langchain\\npip install openai\\npip install faiss-cpu\\npip install chromadb\\n```\\n\\n2. Create a retriever to fetch relevant documents based on the user\\'s query:\\n\\n```python\\nfrom langchain.vectorstores import Chroma\\nfrom langchain.embeddings.openai import OpenAIEmbeddings\\nfrom langchain.retrievers import VectorStoreRetriever\\n\\nembeddings = OpenAIEmbeddings()\\nvectorstore = Chroma(embedding_function=embeddings)\\nretriever = VectorStoreRetriever(vectorstore=vectorstore)\\n```\\n\\n3. Create a LangChain agent that uses the retrieved documents to generate a response:\\n\\n```python\\nfrom langchain.agents import initialize_agent\\nfrom langchain.agents.agent_toolkits import LangchainToolkit\\nfrom langchain.llms import OpenAI\\n\\ntoolkit = LangchainToolkit(retriever=retriever)\\nagent = initialize_agent(toolkit, llm=OpenAI(temperature=0.7))\\n```\\n\\n4. Use the agent to generate a response:\\n\\n```python\\nuser_query = \"How do I build agents with LangChain?\"\\nagent_response = agent.run(user_query)\\nprint(agent_response)\\n```\\n\\nThis solution combines the power of LangChain\\'s retrievers and agents to create a RAG system that can generate',\n",
       " 'intermediate_steps': [(AgentAction(tool='search internet', tool_input='langchain agents rag system tutorial\"\\nObservation', log='To answer this question, I need to find information about using agents in LangChain and how to create a RAG (Red, Amber, Green) system. I will search the internet for relevant documentation and examples.\\n\\nAction: search internet\\nAction Input: \"langchain agents rag system tutorial\"\\nObservation'),\n",
       "   [{'url': 'https://cheatsheet.md/langchain-tutorials/llm-rag.en',\n",
       "     'content': \"This article provides an in-depth understanding of LLM RAG, a vital Language Model in AI, and its working process. We delve into various prompt engineering techniques and their role in enhancing the functionality of LLM RAG. The article also explores practical applications of prompt engineering and its potential to transform LLM RAG's performance.\"},\n",
       "    {'url': 'https://towardsdatascience.com/using-langchain-react-agents-for-answering-multi-hop-questions-in-rag-systems-893208c1847e',\n",
       "     'content': '[Source]\\n--\\n--\\n2\\nWritten by Dr. Varshita Sher\\nTowards Data Science\\nSenior Data Scientist | Explain like I am 5 | Oxford & SFU Alumni | https://podurama.com | Top writer on Medium\\nHelp\\nStatus\\nAbout\\nCareers\\nBlog\\nPrivacy\\nTerms\\nText to speech\\nTeams Sign up\\nSign in\\nSign up\\nSign in\\nMember-only story\\n#LLM FOR BEGINNERS\\nUsing LangChain ReAct Agents for Answering Multi-hop Questions in RAG Systems\\nUseful when answering complex queries on internal documents in a step-by-step manner with ReAct and Open AI Tools agents.\\n Dr. Varshita Sher\\nFollow\\nTowards Data Science\\n--\\n2\\nShare\\nMotivation\\nThe basic RAG chatbots I have built in the past using standard LangChain components such as vectorstore, retrievers, etc have worked out well for me. Depending on the internal dataset I feed in, they are capable of handling humble questions such as “What is the parental leave policy in India” (source dataset: HR policy documents), “What are the main concerns regarding the flavor of our product” (source dataset: social media/Tweets), “What are the themes in Monet paintings” (source dataset: Art Journals), etc. More recently, the complexity of queries being fed to it has increased, for instance, “Has there been an increase in the concerns regarding flavor in the past 1 month”.'},\n",
       "    {'url': 'https://blog.langchain.dev/using-a-knowledge-graph-to-implement-a-devops-rag-application/',\n",
       "     'content': 'Result is the following\\nOf course, you can also ask the chain to produce variable-length path traversals by asking questions like:\\nSome of the mentioned services are the same as in the directly dependent question. Knowledge graph agent\\nSince we have implemented separate tools for the structured and unstructured parts of the knowledge graph, we can add an agent that can use these two tools to explore the knowledge graph.\\n It relies on the following ascii-art type of syntax:\\nThis patterns describes a node with a label Person and the name property Tomaz that has a LIVES_IN relationship to the Country node of Slovenia.\\n The neat thing about LangChain is that it provides a GraphCypherQAChain, which generates the Cypher queries for you, so you don’t have to learn Cypher syntax in order to retrieve information from a graph database like Neo4j.\\n Result is the following\\nYou can also ask the chain to aggregate the data using various grouping keys, like the following example.\\n'},\n",
       "    {'url': 'https://medium.com/@prasadmahamulkar/introduction-to-retrieval-augmented-generation-rag-using-langchain-and-lamaindex-bd0047628e2a',\n",
       "     'content': 'Sign up\\nSign in\\nSign up\\nSign in\\nRetrieval-Augmented Generation (RAG) using LangChain and LlamaIndex\\nStep-by-step implementation\\nPrasad Mahamulkar\\nFollow\\n--\\nListen\\nShare\\nLarge Language Models (LLMs) demonstrate significant capabilities but sometimes generate incorrect but believable responses when they lack information, and this is known as “hallucination.” Website: https://prasadmahamulkar.com/\\nHelp\\nStatus\\nAbout\\nCareers\\nBlog\\nPrivacy\\nTerms\\nText to speech\\nTeams Reference:\\nRetrieval-Augmented Generation for LLMs: A Survey\\nParent Document Retriever langChain Documentation\\nParent Document Reteriver LlamaIndex Documentation\\n--\\n--\\nWritten by Prasad Mahamulkar\\nMSc. Step 8: Finally, set up a query engine by combining the retriever and service context, and add a user query to get a relevant response.\\n The system prioritizes and retrieves the top K chunks showing the highest similarity, using them as an expanded contextual basis to address the user’s request.\\n'},\n",
       "    {'url': 'https://scalexi.medium.com/implementing-a-retrieval-augmented-generation-rag-system-with-openais-api-using-langchain-ab39b60b4d9f',\n",
       "     'content': 'Sign up\\nSign in\\nSign up\\nSign in\\nImplementing a Retrieval-Augmented Generation (RAG) System with OpenAI’s API using LangChain\\nScaleX Innovation\\nFollow\\n--\\n1\\nListen\\nShare\\nAbstract\\nIn this comprehensive guide, you’ll learn how to implement a Retrieval-Augmented Generation (RAG) system using OpenAI’s API using LangChain. Here’s a list of the libraries we’ll be installing:\\nTo install these, run the following commands in your Colab notebook:\\nAfter running these commands, your environment will be equipped with all the necessary tools to build a state-of-the-art RAG system.\\n This approach allows conversational AI to deliver more precise and contextually relevant responses by drawing upon a vast array of external information sources in addition to the model’s internal knowledge\\u200b\\u200b\\u200b\\u200b.\\nIn practice, RAG operates by first formulating a user’s query, then scouring large databases to retrieve pertinent information, selecting the most relevant data, and finally generating a response that is informed by this external knowledge. This not only elevates the quality of the conversation by making it more informative and relevant but also showcases the potential of RAG to transform the capabilities of conversational AIs across various applications\\u200b\\u200b\\u200b\\u200b.\\nThe Intuition Behind Retrieval-Augmented Generation (RAG)\\n Creating the Vector Store: The Heart of RAG\\nAt the heart of our RAG system is the Vector Store, a critical component that powers the searchability and retrieval capabilities of the chatbot.'}])]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": query})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
